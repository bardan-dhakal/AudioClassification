{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8947614,"sourceType":"datasetVersion","datasetId":5384465},{"sourceId":9544189,"sourceType":"datasetVersion","datasetId":5726317}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport librosa\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport tensorflow as tf\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.layers import Dense, Dropout, Input, GlobalAveragePooling2D, Concatenate\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, LearningRateScheduler\nfrom tensorflow.keras.applications import EfficientNetV2B1\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.utils import class_weight\nfrom tensorflow.keras import layers, models, regularizers\n\n\n# Class names for the dataset\nclass_names = [\n    'bus', 'cafe/restaurant', 'car', 'city center', 'forest path', \n    'grocery store', 'home', 'lakeside beach', 'library', 'metro station', \n    'office', 'residential area', 'train', 'tram', 'urban park'\n]\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":" def extract_mfcc(audio_path, n_mfcc=20, n_fft=2048, hop_length=512):\n     y, sr = librosa.load(audio_path, sr=None)\n     mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc, n_fft=n_fft, hop_length=hop_length)\n     mfcc = librosa.power_to_db(mfcc, ref=np.max)\n     return mfcc","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_ivector(csv_path, audio_file_name):\n    df = pd.read_csv(csv_path)\n    \n    \n    # Assuming the CSV has a column 'file_name' that corresponds to the audio file\n    # and other columns represent i-vector values (e.g., ivector_1, ivector_2, ...)\n    ivector_row = df[df['Filename'] == audio_file_name].drop('Filename', axis=1)\n    \n    if not ivector_row.empty:\n        ivector = ivector_row.values.flatten()  # Flatten to a 1D array\n        return ivector\n    else:\n        raise ValueError(f\"i-vector for {audio_file_name} not found in CSV.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_data(audio_dir, csv_path, n_fft=2048, hop_length=512, n_mfcc=20):\n    mfccs = []\n    ivectors = []\n    labels = []\n    file_names = []  \n    \n    for audio_file in os.listdir(audio_dir):\n        if audio_file.endswith('.wav'):\n            audio_path = os.path.join(audio_dir, audio_file)\n            audio_file_name = audio_file  # To match with the CSV file's name\n            \n            # Extract MFCC\n            mfcc = extract_mfcc(audio_path, n_mfcc, n_fft, hop_length)\n            mfcc = StandardScaler().fit_transform(mfcc) # Normalize MFCC\n            mfccs.append(mfcc)\n            \n            # Extract i-vector from CSV\n            ivector = extract_ivector(csv_path, audio_file_name)\n            ivector = np.array(ivector)\n            ivector = StandardScaler().fit_transform(ivector.reshape(1, -1))\n            ivectors.append(ivector)\n            \n            # Concatenate MFCC and i-vector (Fusion)\n            #fused_features = np.concatenate((mfcc.flatten(), ivector.flatten()))\n            #mfccs.append(fused_features)\n            \n            label = int(audio_file.split('_')[-1].replace('class', '').replace('.wav', ''))\n            labels.append(label)\n            file_names.append(audio_file)\n    \n    mfcc_array = np.array(mfccs)\n    print(mfcc_array.shape)\n    ivector_array = np.array(ivectors)\n    print(ivector_array.shape)\n    labels_array = np.array(labels)\n    \n    return mfcc_array, ivector_array, labels_array, file_names","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def prepare_data(audio_dir, csv_path, test_size=0.2, random_state=42, mode='train'):\n    X_mfcc, X_ivector, y, file_names = load_data(audio_dir, csv_path)\n    \n    # Label encoding\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    \n    if mode == 'train': # Train-test split\n        X_train_mfcc, X_val_mfcc, X_train_ivector, X_val_ivector, y_train, y_val, file_names_train, file_names_val = train_test_split(\n        X_mfcc, X_ivector, y, file_names, test_size=test_size, random_state=random_state\n    )\n        return X_train_mfcc, X_val_mfcc, X_train_ivector, X_val_ivector, y_train, y_val, label_encoder.classes_, file_names_train, file_names_val\n    \n    \n    else:\n        return X_mfcc, X_ivector, y, label_encoder.classes_, file_names","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def create_multi_branch_model(mfcc_input_shape, ivector_input_shape, num_classes):\n#     # Input layers\n#     mfcc_input = Input(shape=mfcc_input_shape, name='mfcc_input')\n#     ivector_input = Input(shape=ivector_input_shape, name='ivector_input')\n    \n#     # MFCC branch (you can add more layers if needed)\n#     x_mfcc = layers.Conv2D(32, (3, 3), activation='relu')(mfcc_input)\n#     x_mfcc = layers.MaxPooling2D((2, 2))(x_mfcc)\n#     x_mfcc = GlobalAveragePooling2D()(x_mfcc)\n    \n#     # i-vector branch (fully connected layers)\n#     x_ivector = Dense(128, activation='relu')(ivector_input)\n#     x_ivector = Dropout(0.3)(x_ivector)\n    \n#     # Concatenate branches\n#     concatenated = Concatenate()([x_mfcc, x_ivector])\n    \n#     # Fully connected layers after concatenation\n#     x = Dense(128, activation='relu')(concatenated)\n#     x = Dropout(0.3)(x)\n#     output = Dense(num_classes, activation='softmax')(x)\n    \n#     # Define the model\n#     model = Model(inputs=[mfcc_input, ivector_input], outputs=output)\n    \n#     # Compile the model\n#     model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n    \n#     return model\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# from tensorflow.keras.layers import Input, Conv2D, GlobalAveragePooling2D, Dense, Concatenate, Dropout, Flatten\n# from tensorflow.keras.models import Model\n# from tensorflow.keras.optimizers import Adam\n\n# def create_multi_branch_model(mfcc_input_shape, ivector_input_shape, num_classes):\n#     # MFCC branch\n#     mfcc_input = Input(shape=mfcc_input_shape, name='mfcc_input')\n#     x_mfcc = Conv2D(32, (3, 3), activation='relu')(mfcc_input)\n#     x_mfcc = GlobalAveragePooling2D()(x_mfcc)  # Global average pooling to reduce dimensions\n    \n#     # i-vector branch\n#     ivector_input = Input(shape=ivector_input_shape, name='ivector_input')\n#     x_ivector = Flatten()(ivector_input)  # Flatten to make it 2D\n#     x_ivector = Dense(128, activation='relu')(x_ivector)\n#     x_ivector = Dropout(0.3)(x_ivector)\n    \n#     # Concatenate the outputs of both branches\n#     concatenated = Concatenate()([x_mfcc, x_ivector])\n    \n#     # Dense layers after concatenation\n#     x = Dense(128, activation='relu')(concatenated)\n#     x = Dropout(0.3)(x)\n#     output = Dense(num_classes, activation='softmax')(x)\n\n#     # Define the model\n#     model = Model(inputs=[mfcc_input, ivector_input], outputs=output)\n    \n#     # Compile the model\n#     model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n    \n#     return model\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Conv2D, GlobalAveragePooling2D, Dense, Concatenate, Dropout, Flatten, BatchNormalization\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.regularizers import l2\n\ndef create_multi_branch_model(mfcc_input_shape, ivector_input_shape, num_classes):\n    # MFCC branch\n    mfcc_input = Input(shape=mfcc_input_shape, name='mfcc_input')\n    x_mfcc = Conv2D(64, (3, 3), activation='relu', padding='same')(mfcc_input)\n    x_mfcc = BatchNormalization()(x_mfcc)\n    x_mfcc = Conv2D(64, (3, 3), activation='relu', padding='same')(x_mfcc)\n    x_mfcc = BatchNormalization()(x_mfcc)\n    x_mfcc = GlobalAveragePooling2D()(x_mfcc)  # Global average pooling to reduce dimensions\n\n    # i-vector branch\n    ivector_input = Input(shape=ivector_input_shape, name='ivector_input')\n    x_ivector = Flatten()(ivector_input)  # Flatten to make it 2D\n    x_ivector = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x_ivector)  # Increased units and added L2 regularization\n    x_ivector = Dropout(0.3)(x_ivector)\n    \n    # Concatenate the outputs of both branches\n    concatenated = Concatenate()([x_mfcc, x_ivector])\n    \n    # Dense layers after concatenation with L2 regularization\n    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(concatenated)  # Increased units and added L2 regularization\n    x = Dropout(0.4)(x)  # Increased dropout rate\n    x = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(x)  # Added another dense layer with L2\n    x = Dropout(0.4)(x)  # Increased dropout rate\n    output = Dense(num_classes, activation='softmax')(x)\n\n    # Define the model\n    model = Model(inputs=[mfcc_input, ivector_input], outputs=output)\n    \n    # Compile the model with a lower learning rate\n    model.compile(optimizer=Adam(learning_rate=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])\n    \n    return model\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def evaluate_model(model, X_test_mfcc, X_test_ivector, y_test, file_names, class_names):\n#     test_loss, test_accuracy = model.evaluate([X_test_mfcc, X_test_ivector], y_test)\n#     print(f'Test Loss: {test_loss:.4f}')\n#     print(f'Test Accuracy: {test_accuracy:.4f}')\n    \n#     # Generate predictions\n#     y_pred = model.predict([X_test_mfcc, X_test_ivector])\n#     y_pred_labels = np.argmax(y_pred, axis=1)\n#     y_true_labels = np.argmax(y_test, axis=1)\n\n#     # Print classification report\n#     print(\"\\nClassification Report:\")\n#     print_class_report = classification_report(y_true_labels, y_pred_labels, target_names=class_names)\n#     print(print_class_report)\n#     class_report_dict = classification_report(y_true_labels, y_pred_labels, target_names=class_names, output_dict=True)\n#     save_classification_report(class_report_dict)\n    \n#     # Confusion matrix visualization\n#     cm = confusion_matrix(y_true_labels, y_pred_labels)\n#     plt.figure(figsize=(10, 8))\n#     sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n#     plt.xlabel('Predicted')\n#     plt.ylabel('True')\n#     plt.title('Confusion Matrix')\n#     plt.savefig(\"/kaggle/working/Confusion_Matrix.png\")\n#     plt.show()\n\n#     # Identify and print mispredictions\n#     mispredictions = np.where(y_pred_labels != y_true_labels)[0]\n#     print(f'\\nNumber of mispredictions: {len(mispredictions)}')\n    \n#     for idx in mispredictions:\n#         true_label = class_names[y_true_labels[idx]]\n#         predicted_label = class_names[y_pred_labels[idx]]\n#         confidence_score = y_pred[idx][y_pred_labels[idx]]\n        \n#         print(f'Index: {idx}, File Name: {file_names[idx]}, True Label: {true_label}, Predicted Label: {predicted_label}, Confidence Score: {confidence_score:.4f}')\n#         print('Confidence Scores for all classes:')\n#         for class_idx, class_name in enumerate(class_names):\n#             print(f'  {class_name}: {y_pred[idx][class_idx]:.4f}')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical\n\ndef evaluate_model(model, X_test_mfcc, X_test_ivector, y_test, file_names, class_names):\n    # Convert y_test to one-hot encoding if it's not already\n    if len(y_test.shape) == 1:  # Check if y_test is 1D\n        y_test = to_categorical(y_test, num_classes=len(class_names))\n\n    # Evaluate the model on test data\n    test_loss, test_accuracy = model.evaluate([X_test_mfcc, X_test_ivector], y_test)\n    print(f'Test Loss: {test_loss:.4f}')\n    print(f'Test Accuracy: {test_accuracy:.4f}')\n    \n    # Generate predictions\n    y_pred = model.predict([X_test_mfcc, X_test_ivector])\n    y_pred_labels = np.argmax(y_pred, axis=1)\n    y_true_labels = np.argmax(y_test, axis=1)\n\n    # Print classification report\n    print(\"\\nClassification Report:\")\n    print_class_report = classification_report(y_true_labels, y_pred_labels, target_names=class_names)\n    print(print_class_report)\n    class_report_dict = classification_report(y_true_labels, y_pred_labels, target_names=class_names, output_dict=True)\n    save_classification_report(class_report_dict)\n    \n    # Confusion matrix visualization\n    cm = confusion_matrix(y_true_labels, y_pred_labels)\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title('Confusion Matrix')\n    plt.savefig(\"/kaggle/working/Confusion_Matrix.png\")\n    plt.show()\n\n    # Identify and print mispredictions\n    mispredictions = np.where(y_pred_labels != y_true_labels)[0]\n    print(f'\\nNumber of mispredictions: {len(mispredictions)}')\n    \n    for idx in mispredictions:\n        true_label = class_names[y_true_labels[idx]]\n        predicted_label = class_names[y_pred_labels[idx]]\n        confidence_score = y_pred[idx][y_pred_labels[idx]]\n        \n        print(f'Index: {idx}, File Name: {file_names[idx]}, True Label: {true_label}, Predicted Label: {predicted_label}, Confidence Score: {confidence_score:.4f}')\n        print('Confidence Scores for all classes:')\n        for class_idx, class_name in enumerate(class_names):\n            print(f'  {class_name}: {y_pred[idx][class_idx]:.4f}')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def save_classification_report(class_report_dict):\n    \"\"\"\n    saves classification report, parameter is a dictionary\n    \"\"\"\n    report_df = pd.DataFrame(class_report_dict).transpose()\n    output_path = \"/kaggle/working/classification_report.csv\"\n    report_df.to_csv(output_path, index=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def main(dev_audio_dir, eval_audio_dir, csv_path, eval_csv_path, output_dir, model_path, use_early_stopping=True):\n    \n    if os.path.exists(model_path):\n        print(f\"Loading saved model from {model_path}...\")\n        model = load_model(model_path)\n    \n    else:\n        # Prepare data for training and validation\n        X_train_mfcc, X_val_mfcc, X_train_ivector, X_val_ivector, y_train, y_val, label_classes, file_names_train, file_names_val = prepare_data(dev_audio_dir, csv_path)\n\n        # Ensure correct shape for MFCC input\n        X_train_mfcc = np.expand_dims(X_train_mfcc, axis=-1)\n        X_val_mfcc = np.expand_dims(X_val_mfcc, axis=-1)\n        print(f'Input shape for MFCC training data: {X_train_mfcc.shape}')\n        print(f'Input shape for MFCC validation data: {X_val_mfcc.shape}')\n    \n        # One-hot encode labels\n        y_train_cat = to_categorical(y_train, num_classes=len(label_classes))\n        y_val_cat = to_categorical(y_val, num_classes=len(label_classes))\n\n        # Define input shapes for both branches\n        mfcc_input_shape = X_train_mfcc.shape[1:]  # Shape of MFCC input (e.g., (time, frequency, 1))\n        ivector_input_shape = X_train_ivector.shape[1:]  # Shape of i-vector input (e.g., (ivector_dim,))\n    \n        print(f'MFCC input shape: {mfcc_input_shape}')\n        print(f'i-vector input shape: {ivector_input_shape}')\n\n        # Create multi-branch model\n        model = create_multi_branch_model(mfcc_input_shape, ivector_input_shape, len(label_classes))\n        \n        # Define callbacks\n        callbacks = [\n            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6),#factor = 0.1, patience = 5\n            ModelCheckpoint(os.path.join(output_dir, 'best_model.keras'), save_best_only=True, monitor='val_accuracy')\n        ]\n\n        if use_early_stopping:\n            early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True) #patience = 10\n            callbacks.append(early_stopping)\n        \n        # Compute class weights to handle class imbalance\n        class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n        class_weights_dict = dict(enumerate(class_weights))\n\n        # Train the model\n        history = model.fit(\n            [X_train_mfcc, X_train_ivector], y_train_cat,  # Pass both MFCC and i-vector data\n            validation_data=([X_val_mfcc, X_val_ivector], y_val_cat), \n            epochs=100, batch_size=32, \n            callbacks=callbacks, \n            class_weight=class_weights_dict\n        )\n\n    # Prepare evaluation data\n    X_eval_mfcc, X_eval_ivector, y_eval, eval_label_classes, file_names_eval = prepare_data(eval_audio_dir, eval_csv_path, mode='eval')\n    \n    # Evaluate the model\n    evaluate_model(model, X_eval_mfcc, X_eval_ivector, y_eval, file_names_eval, eval_label_classes)\n\nif __name__ == '__main__':\n    dev_audio_dir = '/kaggle/input/tut-2016/TUT_2016/TUT_Acoustic_scenes_development_all_in_one'\n    eval_audio_dir = '/kaggle/input/tut-2016/TUT_2016/TUT_Acoustic_scenes_evaluation_all_in_one'\n    csv_path = '/kaggle/input/i-vectors/i_vectors-dev-tut.csv'\n    eval_csv_path = '/kaggle/input/i-vectors/i_vectors-eval-tut.csv'\n    output_dir = '/kaggle/working/'\n    model_path = '/kaggle/input/models/best_model.keras'\n    main(dev_audio_dir, eval_audio_dir, csv_path, eval_csv_path, output_dir, model_path, use_early_stopping=True)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}